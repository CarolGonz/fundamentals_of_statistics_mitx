{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#BB0065\">Modes of Convergence</span> \n",
    "$$ X_n \\rightarrow X_o $$\n",
    "\n",
    "* Convergence almost surely\n",
    "     - Not only will any particular $X_n$ be close to $X$ for large $n$, but whole sequence of values will remain close to $X$ with high probability.\n",
    "\n",
    "* Convergence in probability\n",
    "* Convergence in distribution\n",
    "\n",
    "![alt text](https://miro.medium.com/max/875/1*7erwXM4J29h6IfzbeNZmaw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convergence in distribution:\n",
    "* Intuition: It implies that as n grows larger, we become better in modelling the distribution and in turn the next output.\n",
    "* Definition: A series of real number RVs converges in distribution if the cdf of Xn converges to cdf of X as n grows to âˆž\n",
    "\n",
    "![alt image](https://miro.medium.com/max/178/1*a9zLt4I2LSNuOqArq5glZw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ x_n \\rightarrow x_o $$\n",
    "for the real number sequence $x_n$. This means that for any given $\\epsilon>0$, no matter how small, we can exhibit a $m$ such that for any $n>m$, we have\n",
    "\n",
    "$$ \\vert x_n-x_o \\vert < \\epsilon $$\n",
    "\n",
    "\n",
    "Intuitively, this means that once we get past $m$ in the sequence, we get as to within $\\epsilon$ of $x_o$. This means that nothing surprising happens in the sequence on the long march to infinity, which gives a sense of uniformity to the convergence process. When we argue about convergence for statistics, we want to same look-and-feel as we have here, but because we are now talking about random variables, we need other concepts. There are two moving parts for random variables. Recall that random variables are really functions that map sets into the real line: $X:\\Omega \\mapsto \\mathbb{R}$. Thus, one part to keep track of is the behavior of the subsets of $\\Omega$ while arguing about convergence. The other part is the sequence of values that the random variable takes on the real line and how those behave in the convergence process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Almost sure convergence\n",
    "\n",
    "The most straightforward extension into statistics of this convergence concept is convergence with probability one, which is also known as almost sure convergence, which is the following,\n",
    "\n",
    "$$ P\\lbrace \\texttt{for each } \\epsilon>0 \\texttt{ there is } n_\\epsilon>0 \\texttt{ such that for all } n>n_\\epsilon, \\: \\vert X_n-X \\vert < \\epsilon \\rbrace = 1 $$\n",
    "Note the similarity to the prior notion of convergence for real numbers. When this happens, we write this as $X_n \\overset{as}{\\to} X$. In this context, almost sure convergence means that if we take any particular $\\omega\\in\\Omega$ and then look at the sequence of real numbers that are produced by each of the random variables,\n",
    "\n",
    "$$ (X_1(\\omega),X_2(\\omega),X_3(\\omega),\\ldots,X_n(\\omega)) $$\n",
    "then this sequence is just a real-valued sequence in the sense of our convergence on the real line and converges in the same way. If we collect all of the $\\omega$ for which this is true and the measure of that collection equals one, then we have almost sure convergence of the random variable. Notice how the convergence idea applies to both sides of the random variable: the (domain) $\\Omega$ side and the (co-domain) real-valued side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An equivalent and more compact way of writing this is the following,\n",
    "\n",
    "$$ P\\left(\\omega\\in\\Omega \\colon\\lim_{n\\rightarrow\\infty} X_n(\\omega)=X(\\omega) \\right)=1 $$\n",
    "Example. To get some feel for the mechanics of this kind of convergence consider the following sequence of uniformly distributed random variables on the unit interval, $X_n \\sim \\mathcal{U}[0,1]$. Now, consider taking the maximum of the set of $n$ such variables as the following,\n",
    "\n",
    "$$ X_{(n)} = \\max \\lbrace X_1,\\ldots,X_n \\rbrace $$\n",
    "In other words, we scan through a list of $n$ uniformly distributed random variables and pick out the maximum over the set. Intuitively, we should expect that $X_{(n)}$ should somehow converge to one. Let's see if we can make this happen almost surely. We want to exhibit $m$ so that the following is true,\n",
    "\n",
    "$$ P(\\vert 1 - X_{(n)} \\vert) < \\epsilon \\texttt{ when } n>m $$\n",
    "Because $X_{(n)}<1$, we can simplify this as the following,\n",
    "\n",
    "$$ 1-P(X_{(n)}<\\epsilon)=1-(1-\\epsilon)^m \\underset{m\\rightarrow\\infty}{\\longrightarrow} 1 $$\n",
    "Thus, this sequence converges almost surely. We can work this example out in Python using Scipy to make it concrete with the following code,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707840679804043"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "## create a uniform distributuion\n",
    "unif = stats.uniform()\n",
    "\n",
    "## Function to select the max \n",
    "Xn = lambda i: unif.rvs(i).max()\n",
    "\n",
    "# max of Xn with n > 5\n",
    "Xn(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the xn variable is the same as the $X_{(n)}$ random variable in our example. Figure shows a plot of these random variables for different values of $n$ and multiple realizations of each random variable (multiple gray lines). The dark horizontal line is at the 0.95 level. For this example, suppose we are interested in the convergence of the random variable to within 0.05 of one so we are interested in the region between one and 0.95. Thus, in our Equation ref{eq:asconv}, $\\epsilon=0.05$. Now, we have to find $n_\\epsilon$ to get the almost sure convergence. From Figure, as soon as we get past $n>60$, we can see that all the realizations start to fit in the region above the 0.95 horizontal line. However, there are still some cases where a particular realization will skip below this line. To get the probability guarantee of the definition satisfied, we have to make sure that for whatever $n_\\epsilon$ we settle on, the probability of this kind of noncompliant behavior should be extremely small, say, less than 1%. Now, we can compute the following to estimate this probability for $n=60$ over 1000 realizations,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.952"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# probability of n = 60 onver 1000 realizations with 0.95 horizontal line\n",
    "np.mean([Xn(60) > 0.95 for i in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the probability of having a noncompliant case beyond $n>60$ is pretty good, but not still what we are after (0.99). We can solve for the $m$ in our analytic proof of convergence by plugging in our factors for $\\epsilon$ and our desired probability constraint,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.78113496070968\n"
     ]
    }
   ],
   "source": [
    "print(np.log(1-.99)/np.log(.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.994"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean([Xn(90) > 0.95 for i in range(1000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is the result we were looking for. The important thing to understand from this example is that we had to choose convergence criteria for both the values of the random variable (0.95) and for the probability of achieving that level (0.99) in order to compute the $m$. Informally speaking, almost sure convergence means that not only will any particular $X_n$ be close to $X$ for large $n$, but whole sequence of values will remain close to $X$ with high probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence in Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A weaker kind of convergence is convergence in probability which means the following:\n",
    "\n",
    "$$ \\mathbb{P}(\\mid X_n -X\\mid > \\epsilon) \\rightarrow 0 $$\n",
    "as $n \\rightarrow \\infty$ for each $\\epsilon > 0$.\n",
    "\n",
    "This is notationally shown as $X_n \\overset{P}{\\to} X$. For example, let's consider the following sequence of random variables where $X_n = 1/2^n$ with probability $p_n$ and where $X_n=c$ with probability $1-p_n$. Then, we have $X_n \\overset{P}{\\to} 0$ as $p_n \\rightarrow 1$. This is allowable under this notion of convergence because a diminishing amount of non-converging behavior (namely, when $X_n=c$) is possible. Note that we have said nothing about how $p_n \\rightarrow 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example. To get some sense of the mechanics of this kind of convergence, let $\\lbrace X_1,X_2,X_3,\\ldots \\rbrace$ be the indicators of the corresponding intervals,\n",
    "\n",
    "$$ (0,1],(0,\\tfrac{1}{2}],(\\tfrac{1}{2},1],(0,\\tfrac{1}{3}],(\\tfrac{1}{3},\\tfrac{2}{3}],(\\tfrac{2}{3},1] $$\n",
    "In other words, just keep splitting the unit interval into equal chunks and enumerate those chunks with $X_i$. Because each $X_i$ is an indicator function, it takes only two values: zero and one. For example, for $X_2=1$ if $0<x \\le 1/2$ and zero otherwise. Note that $x \\sim \\mathcal{U}(0,1)$. This means that $P(X_2=1)=1/2$. Now, we want to compute the sequence of $P(X_n>\\epsilon)$ for each $n$ for some $\\epsilon\\in (0,1)$. For $X_1$, we have $P(X_1>\\epsilon)=1$ because we already chose $\\epsilon$ in the interval covered by $X_1$. For $X_2$, we have $P(X_2>\\epsilon)=1/2$, for $X_3$, we have $P(X_3>\\epsilon)=1/3$, and so on. This produces the following sequence: $(1,\\frac{1}{2},\\frac{1}{2},\\frac{1}{3},\\frac{1}{3},\\ldots)$. The limit of the sequence is zero so that $X_n \\overset{P}{\\to} 0$. However, for every $x\\in (0,1)$, the sequence of function values of $X_n(x)$ consists of infinitely many zeros and ones (remember that indicator functions can evaluate to either zero or one). Thus, the set of $x$ for which the sequence $X_n(x)$ converges is empty because the sequence bounces between zero and one. This means that almost sure convergence fails here even though we have convergence in probability. The key distinction is that convergence in probability considers the convergence of a sequence of probabilities whereas almost sure convergence is concerned about the sequence of values of the random variables over sets of events that fill out the underlying probability space entirely (i.e., with probability one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good example so let's see if we can make it concrete with some Python. The following is a function to compute the different subintervals,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(n)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_interval = lambda n: np.array(tuple(range(n+1)),tuple(range(1,n+1)))/n\n",
    "make_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use this function to create a Numpy array of intervals, as in the example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 2, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(range(3+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Tuple must have size 2, but has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\MARIA~1.GON\\AppData\\Local\\Temp/ipykernel_24364/2473730491.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mintervals\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_interval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintervals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MARIA~1.GON\\AppData\\Local\\Temp/ipykernel_24364/2473730491.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mintervals\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmake_interval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintervals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\MARIA~1.GON\\AppData\\Local\\Temp/ipykernel_24364/1236009817.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(n)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmake_interval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmake_interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Tuple must have size 2, but has size 1"
     ]
    }
   ],
   "source": [
    "intervals= np.vstack([make_interval(i) for i in range(1,5)])\n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function computes the bit string in our example, $\\lbrace X_1,X_2,\\ldots,X_n \\rbrace$,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these entries should approach the $(1,\\frac{1}{2},\\frac{1}{2},\\frac{1}{3},\\frac{1}{3},\\ldots)$ sequence we found earlier. Figure shows the convergence of these probabilities for a large number of intervals. Eventually, the probability shown on this graph will decrease to zero with large enough $n$. Again, note that the individual sequences of zeros and ones do not converge, but the probabilities of these sequences converge. This is the key difference between almost sure convergence and convergence in probability. Thus, convergence in probability does not imply almost sure convergence. Conversely, almost sure convergence does imply convergence in probability.\n",
    "\n",
    "Convergence in probability for the random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The following notation should help emphasize the difference between almost sure convergence and convergence in probability, respectively,\n",
    "\n",
    "$$ \\begin{align*} P\\left(\\lim_{n\\rightarrow \\infty} \\vert X_n-X\\vert < \\epsilon\\right)&=1 \\texttt{(almost sure convergence)} \\\\\\ \\lim_{n\\rightarrow \\infty} P(\\vert X_n-X\\vert < \\epsilon)&=1 \\texttt{(convergence in probability)} \\end{align*} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6b5d61ac3104b8f3068c0a6f6872e0dfefc4467160938b94fdb65725df33369"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
